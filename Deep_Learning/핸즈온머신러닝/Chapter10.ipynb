{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate 꿀팁 \n",
    "\n",
    "acc, loss = model.evaluate(X_test, y_test, verbose = 2) \n",
    "\n",
    "print('정확도:{:5.2f}%'.format(acc))\n",
    "print('로스:{:5.2f}%'.format(loss))\n",
    "\n",
    "출력 예쁘게 나옴 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential API를 이용한 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 적재 \n",
    "# fashion dataset : 60000 x 28 x 28 크기 \n",
    "fashion_mnist = keras.datasets.fashion_mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 경사 하강법으로 신경망 훈련, 입력 특성의 스케일 조정 필요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련세트와 테스트 세트 분리 \n",
    "X_valid = X_train_full[:5000] / 255.0\n",
    "X_train = X_train_full[5000:] / 255.0\n",
    "y_valid = y_train_full[:5000] / 255.0\n",
    "y_train = y_train_full[5000:] / 255.0\n",
    "X_test = X_test / 255.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 패션 아이템을 나타내기 위한 클래스 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sequential API 사용 모델 만들기\n",
    "$$ 은닉층 연산 : h_{W,b}(X) = \\theta{(XW + b)} $$\n",
    "$$ W : 편향 뉴런을 제외한 모든 연결 가중치 $$\n",
    "$$ 편향 벡터 b : 편향 뉴런과 인공 뉴런 사이의 모든 연결 가중치 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sequential 객체 생성 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential 객체  : 순서대로 연결된 층을 일렬로 쌓아서 구성 \n",
    "\n",
    "# Sequential 객체 생성 \n",
    "model = keras.models.Sequential() \n",
    "\n",
    "\n",
    "# 입력 레이어 \n",
    "    # Flatteen\n",
    "    # 1. 입력 이미지를 1D 배열로 변환 \n",
    "    # 2. X입력 -> X = X.reshape(-1, 1) 연산 \n",
    "# 전처리 \n",
    "model.add(keras.layers.Flatten(input_shape = [ 28, 28] )) \n",
    "\n",
    "# 300개를 가진 Dnese은닉층, relu 활성화함수 사용 \n",
    "# Dense마다 각자 가중치 행렬 관리 \n",
    "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
    "\n",
    "# 배타적 클래스 분류 : 소프트 맥스 \n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sequential 객체 생성 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation = 'relu'),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    # 출력층 \n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 층 : 784 * 300개 연결 가중치 + 300개의 편향 = 235500\n",
    "-> 많은 파라미터 : 과대적합의 위험 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 컴파일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = 'sgd',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 모델 훈련과 평가 \n",
    "➤ 훈련 정확도와, 검증 정확도의 차이로 과대 적합 확인 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,   # 학습 데이터\n",
    "                    epochs = 2,        # 에포크  \n",
    "                    validation_data = (X_valid, y_valid))\n",
    "                                        # 검증 세트 : 각 에포크마다, 손실 및 지표 확인  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # 수직축의 범위를 [0-1] 사이로 설정합니다. \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California Housing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   8.3252       41.            6.98412698 ...    2.55555556\n",
      "    37.88       -122.23      ]\n",
      " [   8.3014       21.            6.23813708 ...    2.10984183\n",
      "    37.86       -122.22      ]\n",
      " [   7.2574       52.            8.28813559 ...    2.80225989\n",
      "    37.85       -122.24      ]\n",
      " ...\n",
      " [   1.7          17.            5.20554273 ...    2.3256351\n",
      "    39.43       -121.22      ]\n",
      " [   1.8672       18.            5.32951289 ...    2.12320917\n",
      "    39.43       -121.32      ]\n",
      " [   2.3886       16.            5.25471698 ...    2.61698113\n",
      "    39.37       -121.24      ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(housing.data)\n",
    "housing.data.shape # 8개의 컬럼, 20640개의 열 \n",
    "# 20640 x 8 행렬 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬의 행, 열 변환되서 들어옴 \n",
    "\n",
    "# 테스트 셋, 사용할 세트 분리\n",
    "X_train_full, X_test, y_train_full, y_test = \\\n",
    "        train_test_split(housing.data, housing.target)\n",
    "\n",
    "# 학습 셋, 검증 셋 분리\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "        train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 77us/sample - loss: 0.8452 - accuracy: 0.0031 - val_loss: 1.0259 - val_accuracy: 0.0034\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 1.4170 - accuracy: 0.0031 - val_loss: 0.4067 - val_accuracy: 0.0034\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4136 - accuracy: 0.0030 - val_loss: 0.3794 - val_accuracy: 0.0034\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3933 - accuracy: 0.0030 - val_loss: 0.3797 - val_accuracy: 0.0034\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3810 - accuracy: 0.0031 - val_loss: 0.3586 - val_accuracy: 0.0034\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3760 - accuracy: 0.0031 - val_loss: 0.3580 - val_accuracy: 0.0034\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3711 - accuracy: 0.0031 - val_loss: 0.3604 - val_accuracy: 0.0034\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3715 - accuracy: 0.0031 - val_loss: 0.3528 - val_accuracy: 0.0034\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3668 - accuracy: 0.0031 - val_loss: 0.3516 - val_accuracy: 0.0034\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3669 - accuracy: 0.0031 - val_loss: 0.3537 - val_accuracy: 0.0034\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3636 - accuracy: 0.0031 - val_loss: 0.3508 - val_accuracy: 0.0034\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3622 - accuracy: 0.0031 - val_loss: 0.3562 - val_accuracy: 0.0034\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3606 - accuracy: 0.0031 - val_loss: 0.3416 - val_accuracy: 0.0034\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3598 - accuracy: 0.0031 - val_loss: 0.3531 - val_accuracy: 0.0034\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3591 - accuracy: 0.0031 - val_loss: 0.3527 - val_accuracy: 0.0034\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3569 - accuracy: 0.0031 - val_loss: 0.3421 - val_accuracy: 0.0034\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3561 - accuracy: 0.0031 - val_loss: 0.3420 - val_accuracy: 0.0034\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3543 - accuracy: 0.0031 - val_loss: 0.3389 - val_accuracy: 0.0034\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3552 - accuracy: 0.0031 - val_loss: 0.3345 - val_accuracy: 0.0034\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3525 - accuracy: 0.0031 - val_loss: 0.3426 - val_accuracy: 0.0034\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "    # 8 개의 칼럼의 데이터들이 입력값으로 들어옴 \n",
    "    # a : 1, 2, 3,.....\n",
    "    # b : 4, 5, 6,.....\n",
    "    # c : 7, 8, 9,.....\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', \n",
    "              optimizer = 'sgd',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 20, \n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/1 - 0s - loss: 0.4200 - accuracy: 0.0025\n",
      "정확도: 0.34%\n",
      "로스: 0.00%\n"
     ]
    }
   ],
   "source": [
    "acc, loss = model.evaluate(X_test, y_test, verbose = 2) \n",
    "\n",
    "print('정확도:{:5.2f}%'.format(acc))\n",
    "print('로스:{:5.2f}%'.format(loss))\n",
    "\n",
    "# X_new = X_test[:3]\n",
    "# y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.legend(['loss', 'accuracy'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.함수형 API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Deep and Wide 신경망 1 (  짧은 경로, 긴 경로 동시 학습 예제 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬의 행, 열 변환되서 들어옴 \n",
    "\n",
    "# 테스트 셋, 사용할 세트 분리\n",
    "X_train_full, X_test, y_train_full, y_test = \\\n",
    "        train_test_split(housing.data, housing.target)\n",
    "\n",
    "# 학습 셋, 검증 셋 분리\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "        train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 구조를 사용하면 신경망이 (깊게 쌓은 층을 사용한) 복잡한 패턴과 (짧은 경로를 사용한) 간단한 규칙을 모두 학습\n",
    "<img src = './img/wide_deep1.jpg' >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 정의 \n",
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "\n",
    "# 입력과 함께 호출 -> 함수형 API \n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(input_)\n",
    "\n",
    "# 첫번째 출력 전달 \n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "\n",
    "# 주어진 입력으로 바로 호출 \n",
    "concat = keras.layers.Concatenate()([input_, hidden1])\n",
    "\n",
    "# 하나의 뉴런과 활성화 함수가 없는 층을 통해, 주어진 입력 바로 호출 \n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "## 모델 빌딩 \n",
    "# 사용할 입력과 출력을 지정, model 생성 \n",
    "model = keras.Model(inputs = [input_], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse',\n",
    "             optimizer = keras.optimizers.SGD(lr= 1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 102us/sample - loss: 1.7212 - val_loss: 0.8720\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 0.8393 - val_loss: 0.7459\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   epochs = 2,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Deep and Wide 신경망 2 (  짧은 경로, 긴 경로 서로 다른 모델 학습 예제 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 일부 특성은 짧은 경로로 전달하고 다른 특성들은 (중복될 수 있습니다) 깊은 경로로 전달  \n",
    "5개 특성(특성 인덱스 0에서 4번까지)을 짧은 경로로 보내고 6개 특성(특성 인덱스 2에서 7번까지)은 깊은 경로로 보낸다  \n",
    "이렇게 모델이 복잡해지면 적어도 가장 중요한 층에는 이 름을 붙이는 것이 좋습니다\n",
    "<img src = './img/wide_deep2.jpg' >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A - - - - - - - - - concat - output \n",
    "B - 은닉1 - 은닉2 /\n",
    "'''\n",
    "input_A = keras.layers.Input(shape=[5], name = 'wide_input')\n",
    "\n",
    "input_B = keras.layers.Input(shape=[6], name = 'deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "\n",
    "output = keras.layers.Dense(1, name='output')(concat) # 단순 출력층 ㄷ\n",
    "\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse',\n",
    "             optimizer = keras.optimizers.SGD(lr= 1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:] \n",
    "\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 2s 150us/sample - loss: 2.6249 - val_loss: 1.1077\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.9204 - val_loss: 0.7678\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train,\n",
    "                   epochs = 2,\n",
    "                   validation_data = ((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### verbose = 2, evaluate 출력 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/1 - 0s - loss: 0.5756\n",
      "mse :  0.8062218585217646\n",
      "3/1 - 0s\n",
      "[[1.5319521]\n",
      " [2.2952976]\n",
      " [1.9162667]]\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test, verbose = 2)\n",
    "print('mse : ', mse_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B), verbose = 2)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.6 콜백 사용하기  :  checkpoint / earlystopping / tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 사용 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist \n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련세트와 테스트 세트 분리 \n",
    "X_valid = X_train_full[:5000] / 255.0\n",
    "X_train = X_train_full[5000:] / 255.0\n",
    "\n",
    "y_valid = y_train_full[:5000] / 255.0\n",
    "y_train = y_train_full[5000:] / 255.0\n",
    "X_test = X_test / 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28) (55000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 모델 저장과 복원  : 11장에서 재사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    \n",
    "    keras.layers.Dense(300, activation = 'relu'),\n",
    "    keras.layers.Dense(200, activation = 'relu'),\n",
    "    \n",
    "    keras.layers.Dense(1, activation = 'tanh')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss = 'mse',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples\n",
      "Epoch 1/3\n",
      "55000/55000 [==============================] - 11s 196us/sample - loss: 0.0077 - accuracy: 0.0998\n",
      "Epoch 2/3\n",
      "55000/55000 [==============================] - 9s 162us/sample - loss: 3.1311e-05 - accuracy: 0.1008\n",
      "Epoch 3/3\n",
      "55000/55000 [==============================] - 9s 161us/sample - loss: 2.5959e-05 - accuracy: 0.1008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fecc08a5610>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "         epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_17 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 295,901\n",
      "Trainable params: 295,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 11장에서 재사용 \n",
    "model.save('my_keras_model.h5') \n",
    "deep_wide_model = keras.models.load_model('my_keras_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### checkpoint\n",
    "- save_best_only : 옵션 통해 켜놓고 자고 일어나면 제일 좋은 놈이 저장되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_best_only\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('fashion_best.h5', save_best_only = True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('fashion_epochs.h5', save_best_only = False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (55000, 1) was passed for an output of shape (None, 10) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-a27ad1e3caa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(X_train, y_train, epochs = 3, \n\u001b[0;32m----> 2\u001b[0;31m                     callbacks=[checkpoint_cb])\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2536\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2538\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    741\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    742\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                            'as the output.')\n",
      "\u001b[0;31mValueError\u001b[0m: A target array with shape (55000, 1) was passed for an output of shape (None, 10) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 3, \n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### earlystopping\n",
    "- patience = 일정 에포크\n",
    "    - patience(일정 에포크) 동안 검증 세트에 대한 점수가 오르지 않으면 훈련을 멈춤 \n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit((X_train, X_train), \n",
    "                    y_train, epochs = 3, \n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 텐서보드 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_log_dir = './testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard  \n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "    log_dir = 'my_log_dir',\n",
    "    histogram_freq = 1,\n",
    "    embeddings_freq = 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "         epochs = 3,\n",
    "         validation_data = (X_valid, y_valid),\n",
    "         callbacks = callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=my_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.legend(['training', 'validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 사용해 예측 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:10]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
