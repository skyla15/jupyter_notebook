{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 불안정한 그레디언트 : 그레디언트 소실과 폭주 문제 \n",
    "- 그레디언트 소실 문제 : 하위층으로 갈수록 그레디언트가 점점 작아지는 경우, 좋은 솔루션으로 수렴이 되지를 않음\n",
    "- 그레디언트 폭주 문제 : 그레디언트가 점점 커져서 발산하는 경우 - 주로 RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.1. 글로럿과 He초기화 \n",
    "- 신호가 죽거나, 폭주, 또는 소멸하지 않기 위해서는\n",
    "    - 각 층의 출력에 대한 분산이 입력에 대한 분산이 같아야 한다.\n",
    "    - 역방향에서 층을 통과하기 전과 후의 그레디언트 분산이 동일해야 한다.\n",
    "        - fan_in 과 fan_out(입력과 출력 연결 갯수)가 같지 않다면 위의 2가지 보장이 안됨 \n",
    "        - 이를 보완하기 위하여 각 층의 연결 가중치 무작위 초기화 \n",
    "- 글로럿 초기화 : 기본적인 케라스의 가중치 초기화 방법        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.2. 수렴하지 않는 활성화 함수\n",
    "- kernel_initializer = he_normal\n",
    "- kernel_initializer = lecun_normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트, 사용 세트 분리 \n",
    "X_train_full, X_test, y_train_full, y_test =\\\n",
    "    train_test_split(housing.data, housing.target)\n",
    "\n",
    "# 학습, 검증 셋 분리 \n",
    "X_train, X_valid, y_train, y_valid =\\\n",
    "    train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5160, 8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5160,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### model 생성 \n",
    "- LeakyRelu\n",
    "    - LeakyReLU(z)=max(αz, z)로 정의\n",
    "    - 하이퍼파라미터 α가 이 함수가 ‘새는leaky’ 정도를 결정합니다. \n",
    "    - 새는 정도란 z < 0일 때 이 함수의 기울기, 일반적으로 0.01 로 설정\n",
    "    - ReLU보다 성능이 항상 좋음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SELU > ELU > LeakyReLU(그리고 변종들) > ReLU > tanh> 로지스틱 순"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 5160 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 2s 133us/sample - loss: 0.9523 - accuracy: 0.0033 - val_loss: 0.4610 - val_accuracy: 0.0025\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 1s 72us/sample - loss: 0.4267 - accuracy: 0.0033 - val_loss: 0.4204 - val_accuracy: 0.0025\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.4188 - accuracy: 0.0033 - val_loss: 0.4149 - val_accuracy: 0.0025\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 0.3852 - accuracy: 0.0033 - val_loss: 0.3924 - val_accuracy: 0.0025\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 1s 76us/sample - loss: 0.3673 - accuracy: 0.0033 - val_loss: 0.3743 - val_accuracy: 0.0025\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 1s 82us/sample - loss: 0.3544 - accuracy: 0.0033 - val_loss: 0.3658 - val_accuracy: 0.0025\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 1s 91us/sample - loss: 0.3422 - accuracy: 0.0033 - val_loss: 0.3626 - val_accuracy: 0.0025\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 1s 94us/sample - loss: 0.3431 - accuracy: 0.0033 - val_loss: 0.3518 - val_accuracy: 0.0025\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 1s 77us/sample - loss: 0.3302 - accuracy: 0.0033 - val_loss: 0.3390 - val_accuracy: 0.0025\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3243 - accuracy: 0.0033 - val_loss: 0.3390 - val_accuracy: 0.0025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb6019bbad0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    \n",
    "    # LeakyRelu \n",
    "    # 층 생성 후, 적용할 층 뒤에 LeakyReLU 적용  \n",
    "    keras.layers.Dense(10, kernel_initializer = 'he_normal'),\n",
    "    keras.layers.LeakyReLU(alpha = 0.3),\n",
    "    \n",
    "    # SELU \n",
    "    keras.layers.Dense(10, kernel_initializer = 'he_normal'),\n",
    "    \n",
    "    # PReLU \n",
    "    keras.layers.PReLU(alpha_initializer='zeros'),\n",
    "    \n",
    "    # SELU \n",
    "    keras.layers.Dense(10, activation = 'selu', \n",
    "                      kernel_initializer = 'lecun_normal'),\n",
    "    \n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = 'mse',\n",
    "             optimized = 'sgd',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "         validation_data = (X_test, y_test),\n",
    "         epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.3. 배치 정규화 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련초기, 그레디언트 소실, 폭주 감소시킬 수 있음\n",
    "- 훈련 중, 그레디언트 소실, 폭주 방지 \n",
    "- 각 층에서 활성화 함수를 통과하기 전, 후 모델에 연산 추가 \n",
    "- 큰 사이즈 훈련시 효과 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- γ(출력 스케일 벡터)와 β(출력 이동 벡터)는 일반적인 역전파를 통해 학습\n",
    "- μ(최종 입력 평균 벡터)와 σ(최종 입력 표준편 차 벡터)는 지수 이동 평균을 사용\n",
    "    - 각 층마다 4개의 파라미터 γ, β, μ, σ 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training 할 때는 mini-batch의 평균과 분산으로 normalize 하고,  \n",
    "Test 할 때는 계산해놓은 이동 평균으로 normalize 한다.\n",
    "\n",
    "- 역전파 학습 :   \n",
    "    γ(출력 스케일 벡터) / β(출력 이동 벡터) ➤ 역전파 통해 추정 \n",
    "\n",
    "- 지수 이동 평균을 통해 추정  \n",
    "    μ(최종 입력 평균 벡터) / σ(최종 입력 표준편 차 벡터) ➤ 지수 이동 평균 사용 추정 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중요 파라미터 \n",
    "    - axis : 학습시키는 데이터의 컬럼 / 피쳐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 적재 \n",
    "# fashion dataset : 60000 x 28 x 28 크기 \n",
    "fashion_mnist = keras.datasets.fashion_mnist \n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 훈련세트와 테스트 세트 분리 \n",
    "X_valid = X_train_full[:5000] / 255.0\n",
    "\n",
    "X_train = X_train_full[5000:] / 255.0\n",
    "\n",
    "y_valid = y_train_full[:5000] / 255.0\n",
    "\n",
    "y_train = y_train_full[5000:] / 255.0\n",
    "\n",
    "X_test = X_test / 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 활성화 함수 이전, 배치 정규과화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치정규화 추가 \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),    \n",
    "    \n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer = 'he_normal'),\n",
    "    \n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer = 'he_normal'),\n",
    "\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 활성화 함수 이후, 배치 정규화 : keras.layers.BatchNormalization() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[28, 28]), \n",
    "    \n",
    "#     keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # 은닉층 : 활성화 함수 지정 안함, use_bias = False\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False), \n",
    "    # 배치 정규화 층 입력\n",
    "    keras.layers.BatchNormalization(),\n",
    "    # 활성함수 입력 \n",
    "    keras.layers.Activation(\"elu\"),\n",
    "    \n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False), \n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"elu\"),\n",
    "    \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 300)               235200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 100)               30000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 267,810\n",
      "Trainable params: 267,010\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    \\n- 아래 그림 \\n    - 정규화 배치 층 파라미터 : 784 * 4 ( γ, β, μ, σ ) = 3136 \\n    - gamma : γ / beta : β, 배치 정규화 층에서 mo\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# 정규화 층 : 784 * 4개의 파라미터가 추가됨 \n",
    "\n",
    "'''    \n",
    "- 아래 그림 \n",
    "    - 정규화 배치 층 파라미터 : 784 * 4 ( γ, β, μ, σ ) = 3136 \n",
    "    - gamma : γ / beta : β, 배치 정규화 층에서 mo\n",
    "'''\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그레이디언트 클리핑 : 배치 정규화가 어려울 때, 그레디언트 < threshold 되도록 clipping 하는 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clipping \n",
    "optimizer = keras.optimizers.SGD(clipvalue=1.0) \n",
    "\n",
    "# Clip norm \n",
    "# l2 norm이 지정한 임곗값보다 클 경우, 그레디언트 클리핑 \n",
    "# optimizer = keras.optimizers.SGD(clipnorm=1.0)\n",
    "\n",
    "model.compile(loss ='sparse_categorical_crossentropy',    \n",
    "              optimizer=optimizer,\n",
    "              metrics = ['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.0910 - accuracy: 0.0994\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 6s 102us/sample - loss: 0.0035 - accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 6s 101us/sample - loss: 0.0018 - accuracy: 0.1008\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 6s 100us/sample - loss: 0.0012 - accuracy: 0.1008\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 6s 111us/sample - loss: 9.2878e-04 - accuracy: 0.1008\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 6s 108us/sample - loss: 7.3674e-04 - accuracy: 0.1008\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 6s 111us/sample - loss: 6.1121e-04 - accuracy: 0.1008\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 5s 91us/sample - loss: 5.1736e-04 - accuracy: 0.1008\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 5s 94us/sample - loss: 4.5001e-04 - accuracy: 0.1008\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 3.9573e-04 - accuracy: 0.1008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5de7a01d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "         epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 사전훈련된 층 재사용하기 : 전이학습  ( MNIST Fashion 데이터셋 재사용 ) \n",
    "- 비슷한 유형의 문제를 처리한 신경망이 이미 있는지 찾아본 다음(14장 참조), 그 신경망의 하위층을 재사용하는 방법 \n",
    "- 보통 원본 모델의 출력층을 바꿔야 합니다. 이 층이 새로운 작업에 가장 유용하지 않는 층이고 새로운 작업에 필요한 출력 개수와 맞지 않을 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/11_2_전이학습.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 새로운 층이 적절한 가중치를 학습할 수 있도록  재사용하는 층을 모두 동결 ( 가중치가 바뀌지 않도록, model.layers[index].trainable = False )     \n",
    "  \n",
    "2. 조금의 수를 3,4번의 에포크를 훈련 후 동결을 해제 model.layers[index].trainable = True    \n",
    "  \n",
    "3. 모델 재컴파일, 동결 해제 후에는 학습률을 낮춤 -> 재사용된 가중치 손상 방지 ( 학습률 : optimizers.최적화함수(lr = rate ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 적재 \n",
    "fashion_mnist = keras.datasets.fashion_mnist \n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# 훈련세트와 테스트 세트 분리 \n",
    "X_valid = X_train_full[:5000] / 255.0\n",
    "X_train = X_train_full[5000:] / 255.0\n",
    "y_valid = y_train_full[:5000] / 255.0\n",
    "y_train = y_train_full[5000:] / 255.0\n",
    "X_test = X_test / 255.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이전 사용하였던 모델을 가져옴 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 이전 데이터셋 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_A의 출력층을 제외한 나머지 층을 가져옴\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "\n",
    "# model_B_on_A의 출력층 추가\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- modeal_A와 model_B_on_A는 층을 공유, 모델_B_on_A를 훈련할 때 model_A도 영향을 받음  \n",
    "- 훈련 시 독립적으로 model_B_on_A를 훈련하고싶다면 clone _model()과 get_weights()를 통해 모델 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "\n",
    "# model_A의 가중치를 가져옴 \n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 기존 가중치 동결, 새로운 층 가중치 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/4\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.0959 - accuracy: 0.1008 - val_loss: 0.0924 - val_accuracy: 0.0914\n",
      "Epoch 2/4\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.0915 - accuracy: 0.1008 - val_loss: 0.0905 - val_accuracy: 0.0914\n",
      "Epoch 3/4\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.0901 - accuracy: 0.1008 - val_loss: 0.0895 - val_accuracy: 0.0914\n",
      "Epoch 4/4\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.0894 - accuracy: 0.1008 - val_loss: 0.0889 - val_accuracy: 0.0914\n"
     ]
    }
   ],
   "source": [
    "# model_B_on_A 새로운 레이어 : 입력 레이어 ~ 출력 직전 레이어 학습 동결 \n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 출력 직전 레이어 ~ 출력 레이어( 새로운 레이어 ) 가중치 학습 \n",
    "# 에포크 약간만 주고 학습 \n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-2),\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B_on_A.fit(X_train, y_train, epochs=4,\n",
    "                           validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 기존 가중치 동결 해제, 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/16\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 2.0876e-04 - accuracy: 0.1008 - val_loss: 1.9012e-04 - val_accuracy: 0.0914\n",
      "Epoch 2/16\n",
      "55000/55000 [==============================] - 6s 101us/sample - loss: 2.0592e-04 - accuracy: 0.1008 - val_loss: 1.8784e-04 - val_accuracy: 0.0914\n",
      "Epoch 3/16\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 2.0340e-04 - accuracy: 0.1008 - val_loss: 1.8582e-04 - val_accuracy: 0.0914\n",
      "Epoch 4/16\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 2.0115e-04 - accuracy: 0.1008 - val_loss: 1.8404e-04 - val_accuracy: 0.0914\n",
      "Epoch 5/16\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 1.9915e-04 - accuracy: 0.1008 - val_loss: 1.8245e-04 - val_accuracy: 0.0914\n",
      "Epoch 6/16\n",
      "55000/55000 [==============================] - 7s 136us/sample - loss: 1.9734e-04 - accuracy: 0.1008 - val_loss: 1.8102e-04 - val_accuracy: 0.0914\n",
      "Epoch 7/16\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 1.9571e-04 - accuracy: 0.1008 - val_loss: 1.7973e-04 - val_accuracy: 0.0914\n",
      "Epoch 8/16\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 1.9423e-04 - accuracy: 0.1008 - val_loss: 1.7856e-04 - val_accuracy: 0.0914\n",
      "Epoch 9/16\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 1.9287e-04 - accuracy: 0.1008 - val_loss: 1.7751e-04 - val_accuracy: 0.0914\n",
      "Epoch 10/16\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 1.9163e-04 - accuracy: 0.1008 - val_loss: 1.7654e-04 - val_accuracy: 0.0914\n",
      "Epoch 11/16\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 1.9049e-04 - accuracy: 0.1008 - val_loss: 1.7565e-04 - val_accuracy: 0.0914\n",
      "Epoch 12/16\n",
      "55000/55000 [==============================] - 7s 122us/sample - loss: 1.8945e-04 - accuracy: 0.1008 - val_loss: 1.7484e-04 - val_accuracy: 0.0914\n",
      "Epoch 13/16\n",
      "55000/55000 [==============================] - 6s 111us/sample - loss: 1.8848e-04 - accuracy: 0.1008 - val_loss: 1.7408e-04 - val_accuracy: 0.0914\n",
      "Epoch 14/16\n",
      "55000/55000 [==============================] - 6s 100us/sample - loss: 1.8757e-04 - accuracy: 0.1008 - val_loss: 1.7338e-04 - val_accuracy: 0.0914\n",
      "Epoch 15/16\n",
      "55000/55000 [==============================] - 5s 97us/sample - loss: 1.8672e-04 - accuracy: 0.1008 - val_loss: 1.7272e-04 - val_accuracy: 0.0914\n",
      "Epoch 16/16\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 1.8593e-04 - accuracy: 0.1008 - val_loss: 1.7212e-04 - val_accuracy: 0.0914\n"
     ]
    }
   ],
   "source": [
    "# 재사용된 층의 동결 해제, 모델 다시 학습 - 재사용된 층을 현재 학습을 튜닝하기 위해 훈련 \n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# 재사용된 층의 동결을 해제 후, 학습률을 낮추어 재사용된 가중치 유지 \n",
    "model_B_on_A.compile(loss=\"mse\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-4),\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B_on_A.fit(X_train, y_train, epochs=16,\n",
    "                           validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 1s - loss: 31.1225 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[28.332090649414063, 0.1]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.legend(['loss', 'val_accuracy'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
