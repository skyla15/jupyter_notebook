{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error , r2_score\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boston 데이타셋 로드\n",
    "boston = load_boston()\n",
    "\n",
    "# boston 데이타셋 DataFrame 변환 \n",
    "bostonDF = pd.DataFrame(boston.data , columns = boston.feature_names)\n",
    "bostonDF['PRICE'] = boston.target\n",
    "\n",
    "y_target = bostonDF['PRICE']\n",
    "X_data = bostonDF.drop(['PRICE'],axis=1,inplace=False)\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X_data , y_target ,test_size=0.3, random_state=156)\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norm이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ {||x||}_p := ({{{\\sum_{i=1}^n{|x_i|}^p}}})^{1 \\over p } $$\n",
    "\n",
    "- p : Norm의 차수\n",
    "    - p = 1 : L1 Norm \n",
    "    - p = 2 : L2 Norm\n",
    "- n : 해당 벡터의 원소 수 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Norm \n",
    "$$ {d_1}(p,q) = {||p-q||}_1 = {{{\\sum_{i=1}^n{{|{p_i} - {q_i}|}}}}}, where\\;(p,q)\\;are\\;vectors $$\n",
    "-  두 벡터 p, q의 각 원소들의 차이의 절댓값의 합 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ {||p||}_1 = {{{\\sum_{i=1}^n{{|{p_i}|}}}}} $$\n",
    "- 한 벡터 원소의 절댓값의 합 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Norm = Euclidean Norm \n",
    "$$ {||p-q||}_2 := \\sqrt{{{\\sum_{i=1}^n{({{p_i} - {q_i}})^2}}}}, where\\;(p,q)\\;are\\;vectors $$\n",
    "- 두 벡터의 직선 거리. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ {||x||}_2 := \\sqrt{{x_1}^2 + ... + {x_n}^2} $$\n",
    "- q가 원점인 경우, 원점으로부터 p까지의 직선거리 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Norm Loss와 L2 Norm Loss \n",
    "- L2 Loss : 오차의 제곱을 더하기 때문에 Outlier에 더 큰 영향 \n",
    "- L1 Loss가 L2 Loss에 비해 Outlier에 대해 더 Robust함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L1 Loss : 아웃라이어가 적당히 무시되길 바랄 경우 사용\n",
    "- L1 Loss : 0인 지점에서 미분 불가능 \n",
    "- L2 Loss : 아웃라이어에 신경써야 할 경우 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Loss\n",
    "- LAD(Least Absolute Deviations), \n",
    "- LAE(Least Absolute Errors), LAV(Least Absolute Value), Least Absolute Residual(LAR) \n",
    "- Sum of absolute deviations \n",
    "\n",
    "$$ L = \\sum_{i=1}^n{|{y_i}-{f(x_i)}|} $$\n",
    "- 실제 값($y_i$)과 예측치(${f(x_i)}$) 사이의 절대 오차값들의 합\n",
    "<img src = './img/06_Lasso2.jpg' width = '30%' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Loss \n",
    "- LSE (Least Squares Error) \n",
    "$$ L = \\sum_{i=1}^n{(y_i - {(f{x_i})})^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function과 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __RSS : Residual Sum of Square__ ( 회귀 )\n",
    "\n",
    "$$ J = Cost(w) = RSS = {1 \\over m}{\\sum_{i=1}^m}{(Wx^{(i)} - y^{(i)})}^2 $$\n",
    "\n",
    "### Gradient Descent Algorithm \n",
    "\n",
    "$ 1)\\quad \\hat y = wX $\n",
    "\n",
    "$ 2)\\quad 위의 식에서 W값을 기울기로 취급하고, 기존의 상수 {1 \\over m}을 {1 \\over 2m}으로 변경하여 미분을 쉽게 해준다 $\n",
    "\n",
    "$ 3)\\quad Cost(w) = RSS = {(wX - y)}{(wX - y)}^t $\n",
    "\n",
    "$ 4)\\quad W\\;미분 진행 $\n",
    "\n",
    "$ 5)\\quad w := w - \\alpha{\\partial \\over \\partial w}cost(w) = w - {\\partial \\over \\partial w}{(wX - y)}{(wX - y)}^t $\n",
    "\n",
    "$ 6)\\quad W := W - ( 2X^tXw - 2X^ty )  $\n",
    "\n",
    "\n",
    "$ \\alpha는\\; 수정이\\; 반복될\\; 때,\\; 다음 \\; 점을\\; 어느정도\\; 옮길\\; 지\\; 결정하는\\; 상수 $\n",
    "\n",
    "$ 최소점\\; 0에서\\; 우측에\\; 점이\\; 위치한다면\\; 기울기는\\; 양수,\\; 우측에\\; 있다면\\; 기울기는\\; 음수가\\; 된다.\\;즉,\\;0을\\; 기준으로\\; 우측에\\; 있다면\\; 작은\\; 곳으로 움직이고,\\; 좌측에\\; 있다면\\; 큰\\; 쪽으로\\; W를\\; 이동시키기\\; 위해,\\; 음수를\\; 곱하여\\; 이동시킨다$\n",
    "\n",
    "$$W := W - \\alpha{1 \\over m}{\\sum_{i=1}^m}{(Wx^{(i)} - y^{(i)})}x^{(i)} $$\n",
    "$$ W := W - ( 2X^tXw - 2X^ty )  $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf) RSS 타원의 모양\n",
    "- '2차원' 공간에서 $ {aw_0}^2 + {bw_0}{w_1} + {cw_1}^2 = S $ : 타원 방정식 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization \n",
    "- 참고 : https://youtu.be/5asL5Eq2x0A\n",
    "- 왜 정규화?\n",
    "    - 편향-분산 트레이드 오프를 위해 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization ( Ridge Regularization ) \n",
    "from sklearn.linear_model import Ridge\n",
    "- 파라미터\n",
    "    - alpha : 아래의 식에서 lambda의 값, 즉 규제의 크기 결정 계수\n",
    "- 속성 \n",
    "    - coef_ : 각 feature에 대한 weight 벡터 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 정규화 (Ridge Regression) \n",
    "    - 편향(Bias)를 줄여준다. \n",
    "<img src = './img/06_Regit1.jpg' width = '40%' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ min({||Y-wX||}_2^2 + \\lambda ||w||_2^2 )\\; where \\; \\lambda \\; is\\;penalty$$\n",
    "- 위의 식을 만족하는 회귀 계수 벡터 w는 RSS 공간에서의 계수들과 $ \\lambda ||w||_2^2 <= S$의 원 내부의 계수들 중에서 가장 작은 RSS를 갖는다. \n",
    "- $\\lambda$는 이 원의 크기를 조절하고, $\\lambda$ 값이 RSS 범위까지 포함한다면, 단순한 RSS 모델과 차이가 없어진다\n",
    "- 원의 경계(Ridge)에서 만날 경우, 파라미터들을 최소화시킬 수 있다.\n",
    "- 특히 $\\lambda$값이 커질수록 회귀 계수들의 크기가 작아진다\n",
    "- 작아진 회귀 계수들은 feature들 간의 다중공선성을 갖는 것을 방지해준다 \n",
    "<img src = './img/06_Regit3.jpg' width = '30%' >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정리 \n",
    "1) 계수들은 0에 까깝도록 줄여줌   \n",
    "2) feature selection에 사용될 수 없음   \n",
    "3) 상관관계에 있는 변수들의 계수를 작게 만드러줌   \n",
    "4) 모든 계수들이 중요할 때 사용   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 릿지 회귀 RMSE, k-fold ( cv = 5 ) 계산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 folds 의 개별 Negative MSE scores:  [-11.422 -24.294 -28.144 -74.599 -28.517]\n",
      " 5 folds 의 개별 RMSE scores :  [3.38  4.929 5.305 8.637 5.34 ]\n",
      " 5 folds 의 평균 RMSE : 5.518 \n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha = 10)\n",
    "\n",
    "# 데이터 : 보스턴 집값 데이터 \n",
    "neg_mse_scores = cross_val_score(ridge, X_data, y_target, scoring = 'neg_mean_squared_error', cv = 5)\n",
    "# RMSE 계산 \n",
    "rmse_scores = np.sqrt( -1*neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(' 5 folds 의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 3))\n",
    "print(' 5 folds 의 개별 RMSE scores : ', np.round(rmse_scores,3))\n",
    "print(' 5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ridge : alpha에 따른 값 변화  ( $ \\alpha ( \\lambda ) = 0, 0.1, 1, 10, 100 \\;$) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0 일 때 5 folds 의 평균 RMSE : 5.829 \n",
      "alpha 0.1 일 때 5 folds 의 평균 RMSE : 5.788 \n",
      "alpha 1 일 때 5 folds 의 평균 RMSE : 5.653 \n",
      "alpha 10 일 때 5 folds 의 평균 RMSE : 5.518 \n",
      "alpha 100 일 때 5 folds 의 평균 RMSE : 5.330 \n",
      "\n",
      "best score : 5.33, when alpha = 100\n"
     ]
    }
   ],
   "source": [
    "# Ridge에 사용될 alpha 파라미터의 값들을 정의\n",
    "alphas = [0 , 0.1 , 1 , 10 , 100]\n",
    "\n",
    "best_score = math.inf\n",
    "alpha = -1\n",
    "# alphas list 값을 iteration하면서 alpha에 따른 평균 rmse 구함.\n",
    "for alpha in alphas :\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    \n",
    "    #cross_val_score를 이용하여 5 fold의 평균 RMSE 계산\n",
    "    neg_mse_scores = cross_val_score(ridge, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    \n",
    "    avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "    print('alpha {0} 일 때 5 folds 의 평균 RMSE : {1:.3f} '.format(alpha,avg_rmse))\n",
    "    \n",
    "    if best_score > avg_rmse:\n",
    "        best_score = avg_rmse\n",
    "        alpha = alpha\n",
    "print('\\nbest score : {}, when alpha = {}'.format(np.round(best_score,3), alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ridge 회귀 계수 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 alpha에 따른 회귀 계수 값을 시각화하기 위해 5개의 열로 된 맷플롯립 축 생성  \n",
    "fig , axs = plt.subplots(figsize=(18,6) , nrows=1 , ncols=5)\n",
    "# 각 alpha에 따른 회귀 계수 값을 데이터로 저장하기 위한 DataFrame 생성  \n",
    "coeff_df = pd.DataFrame()\n",
    "\n",
    "# alphas 리스트 값을 차례로 입력해 회귀 계수 값 시각화 및 데이터 저장. pos는 axis의 위치 지정\n",
    "for pos , alpha in enumerate(alphas) :\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_data , y_target)\n",
    "    \n",
    "    # alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 컬럼으로 추가.  \n",
    "    coeff = pd.Series(data=ridge.coef_ , index=X_data.columns )\n",
    "    \n",
    "    colname='alpha:'+str(alpha)\n",
    "    coeff_df[colname] = coeff\n",
    "    \n",
    "    # 막대 그래프로 각 alpha 값에서의 회귀 계수를 시각화. 회귀 계수값이 높은 순으로 표현\n",
    "    coeff = coeff.sort_values(ascending=False)\n",
    "    axs[pos].set_title(colname)\n",
    "    axs[pos].set_xlim(-3,6)\n",
    "    sns.barplot(x=coeff.values , y=coeff.index, ax=axs[pos])\n",
    "\n",
    "# for 문 바깥에서 맷플롯립의 show 호출 및 alpha에 따른 피처별 회귀 계수를 DataFrame으로 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha:0</th>\n",
       "      <th>alpha:0.1</th>\n",
       "      <th>alpha:1</th>\n",
       "      <th>alpha:10</th>\n",
       "      <th>alpha:100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.809865</td>\n",
       "      <td>3.818233</td>\n",
       "      <td>3.854000</td>\n",
       "      <td>3.702272</td>\n",
       "      <td>2.334536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>2.686734</td>\n",
       "      <td>2.670019</td>\n",
       "      <td>2.552393</td>\n",
       "      <td>1.952021</td>\n",
       "      <td>0.638335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.306049</td>\n",
       "      <td>0.303515</td>\n",
       "      <td>0.290142</td>\n",
       "      <td>0.279596</td>\n",
       "      <td>0.315358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.046420</td>\n",
       "      <td>0.046572</td>\n",
       "      <td>0.047443</td>\n",
       "      <td>0.049579</td>\n",
       "      <td>0.054496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.020559</td>\n",
       "      <td>0.015999</td>\n",
       "      <td>-0.008805</td>\n",
       "      <td>-0.042962</td>\n",
       "      <td>-0.052826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.009393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.000692</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>-0.005415</td>\n",
       "      <td>-0.010707</td>\n",
       "      <td>0.001212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.012335</td>\n",
       "      <td>-0.012421</td>\n",
       "      <td>-0.012912</td>\n",
       "      <td>-0.013993</td>\n",
       "      <td>-0.015856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.108011</td>\n",
       "      <td>-0.107474</td>\n",
       "      <td>-0.104595</td>\n",
       "      <td>-0.101435</td>\n",
       "      <td>-0.102202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.524758</td>\n",
       "      <td>-0.525966</td>\n",
       "      <td>-0.533343</td>\n",
       "      <td>-0.559366</td>\n",
       "      <td>-0.660764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.952747</td>\n",
       "      <td>-0.940759</td>\n",
       "      <td>-0.876074</td>\n",
       "      <td>-0.797945</td>\n",
       "      <td>-0.829218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.475567</td>\n",
       "      <td>-1.459626</td>\n",
       "      <td>-1.372654</td>\n",
       "      <td>-1.248808</td>\n",
       "      <td>-1.153390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-17.766611</td>\n",
       "      <td>-16.684645</td>\n",
       "      <td>-10.777015</td>\n",
       "      <td>-2.371619</td>\n",
       "      <td>-0.262847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           alpha:0  alpha:0.1    alpha:1  alpha:10  alpha:100\n",
       "RM        3.809865   3.818233   3.854000  3.702272   2.334536\n",
       "CHAS      2.686734   2.670019   2.552393  1.952021   0.638335\n",
       "RAD       0.306049   0.303515   0.290142  0.279596   0.315358\n",
       "ZN        0.046420   0.046572   0.047443  0.049579   0.054496\n",
       "INDUS     0.020559   0.015999  -0.008805 -0.042962  -0.052826\n",
       "B         0.009312   0.009368   0.009673  0.010037   0.009393\n",
       "AGE       0.000692  -0.000269  -0.005415 -0.010707   0.001212\n",
       "TAX      -0.012335  -0.012421  -0.012912 -0.013993  -0.015856\n",
       "CRIM     -0.108011  -0.107474  -0.104595 -0.101435  -0.102202\n",
       "LSTAT    -0.524758  -0.525966  -0.533343 -0.559366  -0.660764\n",
       "PTRATIO  -0.952747  -0.940759  -0.876074 -0.797945  -0.829218\n",
       "DIS      -1.475567  -1.459626  -1.372654 -1.248808  -1.153390\n",
       "NOX     -17.766611 -16.684645 -10.777015 -2.371619  -0.262847"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df.sort_values(by='alpha:0', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularization ( Lasso Regression )\n",
    "from sklearn.linear_model import Lasso\n",
    "- 파라미터 \n",
    "    - alpha : 규제 크기 \n",
    "- 속성 \n",
    "    - coef_ : 각 feture에 대한 weight 벡터 \n",
    "- Least Absolute Shrinkage and Slection Operater\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression \n",
    "- L1 정규화 ( Lasso 정규화 )\n",
    "<img src = './img/06_Lasso3.jpg' width = '40%' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ min({||Y-wX||}_2^2 + \\lambda ||w||_1 ) where \\; \\lambda \\; is\\;penalty$\n",
    "- 회귀 계수 w는 RSS 공간과 $||w||_1 <= S$의 공간과의 경계점(면)에서 최솟값을 갖음 \n",
    "- $\\lambda$는 이 마름모의 크기를 조절하고, $\\lambda$ 값이 RSS 범위까지 포함한다면, 단순한 RSS 모델과 차이가 없어진다\n",
    "- 또 아래 그림과 같이 $\\beta_1 = 0$인 지점에서 만나게 될 경우, 즉 회귀 계수가 0이 되어 다른 중요도가 높은 변수를 선택하게 됨. \n",
    "이런 이유로 **Lasso 방식은 많은 Feature를 갖고 있을 때 사용하도록 함** \n",
    "- 하지만 Feature를 자동으로 채택하게 되면서, 정보가 손실되게 될 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './img/06_Lasso2.jpg' width = '30%' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정리 \n",
    "1) 일부 계수들을 0으로 줄여준다 -> 이 과정에서 alpha값에 의해 회귀 계수 값이 급격히 변동 가능   \n",
    "2) Feature Selection 역할 가능   \n",
    "3) 상관관계에 있는 계수들이 관련이 없도록 만들어준다   \n",
    "4) 일부 feature들은 무시해도 될 때 사용한다  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 해당 정규화의 의미는 아래와 같이, $||w||_1 <= s$의 내부의 변수들로, 회귀 계수들을 한정짓는 다는 의미로, 어떤 한도(S) 내에 있다는 **제한조건**하에서 RSS를 최소로 하는 계수 추정치들의 집합을 찾고하는 것 \n",
    "<img src = './img/06_Lasso1.jpg' width = '40%' >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "\n",
    "# alpha값에 따른 회귀 모델의 폴드 평균 RMSE를 출력하고 회귀 계수값들을 DataFrame으로 반환 \n",
    "def get_linear_reg_eval(model_name, params=None, X_data_n=None, y_target_n=None, verbose=True):\n",
    "    coeff_df = pd.DataFrame()\n",
    "    if verbose : print('####### ', model_name , '#######')\n",
    "    for param in params:\n",
    "        if model_name =='Ridge': model = Ridge(alpha=param)\n",
    "        elif model_name =='Lasso': model = Lasso(alpha=param)\n",
    "        elif model_name =='ElasticNet': model = ElasticNet(alpha=param, l1_ratio=0.7)\n",
    "        neg_mse_scores = cross_val_score(model, X_data_n, \n",
    "                                             y_target_n, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "        avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "        \n",
    "        print('alpha {0}일 때 5 폴드 세트의 평균 RMSE: {1:.3f} '.format(param, avg_rmse))\n",
    "        \n",
    "        # cross_val_score는 evaluation metric만 반환하므로 모델을 다시 학습하여 회귀 계수 추출\n",
    "        model.fit(X_data , y_target)\n",
    "        \n",
    "        # alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 컬럼으로 추가. \n",
    "        coeff = pd.Series(data=model.coef_ , index=X_data.columns )\n",
    "        colname='alpha:'+str(param)\n",
    "        coeff_df[colname] = coeff\n",
    "    return coeff_df\n",
    "# end of get_linear_regre_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######  Lasso #######\n",
      "alpha 0.07일 때 5 폴드 세트의 평균 RMSE: 5.612 \n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 5.615 \n",
      "alpha 0.5일 때 5 폴드 세트의 평균 RMSE: 5.669 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 5.776 \n",
      "alpha 3일 때 5 폴드 세트의 평균 RMSE: 6.189 \n"
     ]
    }
   ],
   "source": [
    "# 라쏘에 사용될 alpha 파라미터의 값들을 정의하고 get_linear_reg_eval() 함수 호출\n",
    "lasso_alphas = [ 0.07, 0.1, 0.5, 1, 3]\n",
    "coeff_lasso_df =get_linear_reg_eval('Lasso', params=lasso_alphas, X_data_n = X_data, y_target_n =y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lasso 회귀 계수 확인 : 계수 = 0 으로 수렵한 feature 확인 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha:0.07</th>\n",
       "      <th>alpha:0.1</th>\n",
       "      <th>alpha:0.5</th>\n",
       "      <th>alpha:1</th>\n",
       "      <th>alpha:3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.789725</td>\n",
       "      <td>3.703202</td>\n",
       "      <td>2.498212</td>\n",
       "      <td>0.949811</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>1.434343</td>\n",
       "      <td>0.955190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.270936</td>\n",
       "      <td>0.274707</td>\n",
       "      <td>0.277451</td>\n",
       "      <td>0.264206</td>\n",
       "      <td>0.061864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.049059</td>\n",
       "      <td>0.049211</td>\n",
       "      <td>0.049544</td>\n",
       "      <td>0.049165</td>\n",
       "      <td>0.037231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.010248</td>\n",
       "      <td>0.010249</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.006510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>-0.011706</td>\n",
       "      <td>-0.010037</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.020910</td>\n",
       "      <td>0.042495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.014290</td>\n",
       "      <td>-0.014570</td>\n",
       "      <td>-0.015442</td>\n",
       "      <td>-0.015212</td>\n",
       "      <td>-0.008602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>-0.042120</td>\n",
       "      <td>-0.036619</td>\n",
       "      <td>-0.005253</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.098193</td>\n",
       "      <td>-0.097894</td>\n",
       "      <td>-0.083289</td>\n",
       "      <td>-0.063437</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.560431</td>\n",
       "      <td>-0.568769</td>\n",
       "      <td>-0.656290</td>\n",
       "      <td>-0.761115</td>\n",
       "      <td>-0.807679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.765107</td>\n",
       "      <td>-0.770654</td>\n",
       "      <td>-0.758752</td>\n",
       "      <td>-0.722966</td>\n",
       "      <td>-0.265072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.176583</td>\n",
       "      <td>-1.160538</td>\n",
       "      <td>-0.936605</td>\n",
       "      <td>-0.668790</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         alpha:0.07  alpha:0.1  alpha:0.5   alpha:1   alpha:3\n",
       "RM         3.789725   3.703202   2.498212  0.949811  0.000000\n",
       "CHAS       1.434343   0.955190   0.000000  0.000000  0.000000\n",
       "RAD        0.270936   0.274707   0.277451  0.264206  0.061864\n",
       "ZN         0.049059   0.049211   0.049544  0.049165  0.037231\n",
       "B          0.010248   0.010249   0.009469  0.008247  0.006510\n",
       "NOX       -0.000000  -0.000000  -0.000000 -0.000000  0.000000\n",
       "AGE       -0.011706  -0.010037   0.003604  0.020910  0.042495\n",
       "TAX       -0.014290  -0.014570  -0.015442 -0.015212 -0.008602\n",
       "INDUS     -0.042120  -0.036619  -0.005253 -0.000000 -0.000000\n",
       "CRIM      -0.098193  -0.097894  -0.083289 -0.063437 -0.000000\n",
       "LSTAT     -0.560431  -0.568769  -0.656290 -0.761115 -0.807679\n",
       "PTRATIO   -0.765107  -0.770654  -0.758752 -0.722966 -0.265072\n",
       "DIS       -1.176583  -1.160538  -0.936605 -0.668790 -0.000000"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 반환된 coeff_lasso_df를 첫번째 컬럼순으로 내림차순 정렬하여 회귀계수 DataFrame출력\n",
    "sort_column = 'alpha:'+str(lasso_alphas[0])\n",
    "coeff_lasso_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Regularization \n",
    "from sklearn.linear_model import ElasticNet\n",
    "- 파라미터 \n",
    "    - alpha : a + b \n",
    "    - l1_ratio : $ a \\over (a+b) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './img/05_엘라스틱 .jpg' width = '50%' height = '50%' >\n",
    "$ min({||Y-wX||}_2^2 +  aL1 + bL2  ) $에서  $ aL1 + bL2 $의 형태  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라쏘 회귀는 상관관계 높은 피처 중 중요 피처만 선택하고 나머지 피쳐는 0으로 만드는 경향이 강함. 이 과정에서 alpha값에 의한 회귀 계수의 값이 급격히 변동 가능\n",
    "    - 이를 완화하기 위해 L2 규제를 추가한 것 \n",
    "- L1과 L2 규제의 결합으로 인해 시간이 오래 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######  ElasticNet #######\n",
      "alpha 0.07일 때 5 폴드 세트의 평균 RMSE: 5.542 \n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 5.526 \n",
      "alpha 0.5일 때 5 폴드 세트의 평균 RMSE: 5.467 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 5.597 \n",
      "alpha 3일 때 5 폴드 세트의 평균 RMSE: 6.068 \n"
     ]
    }
   ],
   "source": [
    "# 엘라스틱넷에 사용될 alpha 파라미터의 값들을 정의하고 get_linear_reg_eval() 함수 호출\n",
    "# l1_ratio는 0.7로 고정\n",
    "elastic_alphas = [ 0.07, 0.1, 0.5, 1, 3]\n",
    "coeff_elastic_df =get_linear_reg_eval('ElasticNet', params=elastic_alphas,\n",
    "                                      X_data_n = X_data, y_target_n = y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha:0.07</th>\n",
       "      <th>alpha:0.1</th>\n",
       "      <th>alpha:0.5</th>\n",
       "      <th>alpha:1</th>\n",
       "      <th>alpha:3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.574162</td>\n",
       "      <td>3.414154</td>\n",
       "      <td>1.918419</td>\n",
       "      <td>0.938789</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>1.330724</td>\n",
       "      <td>0.979706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.278880</td>\n",
       "      <td>0.283443</td>\n",
       "      <td>0.300761</td>\n",
       "      <td>0.289299</td>\n",
       "      <td>0.146846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.050107</td>\n",
       "      <td>0.050617</td>\n",
       "      <td>0.052878</td>\n",
       "      <td>0.052136</td>\n",
       "      <td>0.038268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.010122</td>\n",
       "      <td>0.010067</td>\n",
       "      <td>0.009114</td>\n",
       "      <td>0.008320</td>\n",
       "      <td>0.007020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>-0.010116</td>\n",
       "      <td>-0.008276</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>0.043446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.014522</td>\n",
       "      <td>-0.014814</td>\n",
       "      <td>-0.016046</td>\n",
       "      <td>-0.016218</td>\n",
       "      <td>-0.011417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>-0.044855</td>\n",
       "      <td>-0.042719</td>\n",
       "      <td>-0.023252</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.099468</td>\n",
       "      <td>-0.099213</td>\n",
       "      <td>-0.089070</td>\n",
       "      <td>-0.073577</td>\n",
       "      <td>-0.019058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-0.175072</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.574822</td>\n",
       "      <td>-0.587702</td>\n",
       "      <td>-0.693861</td>\n",
       "      <td>-0.760457</td>\n",
       "      <td>-0.800368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.779498</td>\n",
       "      <td>-0.784725</td>\n",
       "      <td>-0.790969</td>\n",
       "      <td>-0.738672</td>\n",
       "      <td>-0.423065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.189438</td>\n",
       "      <td>-1.173647</td>\n",
       "      <td>-0.975902</td>\n",
       "      <td>-0.725174</td>\n",
       "      <td>-0.031208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         alpha:0.07  alpha:0.1  alpha:0.5   alpha:1   alpha:3\n",
       "RM         3.574162   3.414154   1.918419  0.938789  0.000000\n",
       "CHAS       1.330724   0.979706   0.000000  0.000000  0.000000\n",
       "RAD        0.278880   0.283443   0.300761  0.289299  0.146846\n",
       "ZN         0.050107   0.050617   0.052878  0.052136  0.038268\n",
       "B          0.010122   0.010067   0.009114  0.008320  0.007020\n",
       "AGE       -0.010116  -0.008276   0.007760  0.020348  0.043446\n",
       "TAX       -0.014522  -0.014814  -0.016046 -0.016218 -0.011417\n",
       "INDUS     -0.044855  -0.042719  -0.023252 -0.000000 -0.000000\n",
       "CRIM      -0.099468  -0.099213  -0.089070 -0.073577 -0.019058\n",
       "NOX       -0.175072  -0.000000  -0.000000 -0.000000 -0.000000\n",
       "LSTAT     -0.574822  -0.587702  -0.693861 -0.760457 -0.800368\n",
       "PTRATIO   -0.779498  -0.784725  -0.790969 -0.738672 -0.423065\n",
       "DIS       -1.189438  -1.173647  -0.975902 -0.725174 -0.031208"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 반환된 coeff_elastic_df를 첫번째 컬럼순으로 내림차순 정렬하여 회귀계수 DataFrame출력\n",
    "sort_column = 'alpha:'+str(elastic_alphas[0])\n",
    "coeff_elastic_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형 회귀 모델을 위한 데이터 변환 : 스케일링/정규화 수행하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. StandardScaler / MinMaxScaler를 이용해서 표준화 혹은 정규화 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "b. PolynomialFeatures를 통해 항을 추가하여 재수행   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. __로그 변환 : 원래 값에 log함수를 적용할 경우 좀 더 정규분포에 가까운 형태로 값이 분포. 일반적인 방법__\n",
    "    - a. 방법 : 예측 성능 기대를 크게 기대하기 어려움\n",
    "    - b. 방법 : 과적합 이슈가 생길 수 있음 \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형 회귀 모델의 가정   \n",
    "    - 피처와 타깃 간에 선형의 관계  \n",
    "    - 피처와 타깃 값의 분포는 정규 분포를 따름   \n",
    "- 피처 혹은 타깃이 Skewness가 강한 분포를 갖는 경우 예측 성능에 부정적인 영향\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형 회귀 모델을 위한 데이터 변환\n",
    "- 선형 모델 사용할 때, 로그변형 시 가장 좋은 값이 나옴 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "# method는 표준 정규 분포 변환(Standard), 최대값/최소값 정규화(MinMax), 로그변환(Log) 결정\n",
    "# p_degree는 다향식 특성을 추가할 때 적용. p_degree는 2이상 부여하지 않음. \n",
    "def get_scaled_data(method='None', p_degree=None, input_data=None):\n",
    "    # 스케일링 : StandardScaler / MinMaxScaler \n",
    "    if method == 'Standard':\n",
    "        scaled_data = StandardScaler().fit_transform(input_data)\n",
    "    elif method == 'MinMax':\n",
    "        scaled_data = MinMaxScaler().fit_transform(input_data)\n",
    "    # 로그변호나 \n",
    "    elif method == 'Log':\n",
    "        scaled_data = np.log1p(input_data)\n",
    "    else:\n",
    "        scaled_data = input_data\n",
    "\n",
    "    if p_degree != None:\n",
    "        scaled_data = PolynomialFeatures(degree=p_degree, \n",
    "                                         include_bias=False).fit_transform(scaled_data)\n",
    "    \n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 변환 유형:None, Polynomial Degree:None\n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 5.788 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 5.653 \n",
      "alpha 10일 때 5 폴드 세트의 평균 RMSE: 5.518 \n",
      "alpha 100일 때 5 폴드 세트의 평균 RMSE: 5.330 \n",
      "\n",
      "## 변환 유형:Standard, Polynomial Degree:None\n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 5.826 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 5.803 \n",
      "alpha 10일 때 5 폴드 세트의 평균 RMSE: 5.637 \n",
      "alpha 100일 때 5 폴드 세트의 평균 RMSE: 5.421 \n",
      "\n",
      "## 변환 유형:Standard, Polynomial Degree:2\n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 8.827 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 6.871 \n",
      "alpha 10일 때 5 폴드 세트의 평균 RMSE: 5.485 \n",
      "alpha 100일 때 5 폴드 세트의 평균 RMSE: 4.634 \n",
      "\n",
      "## 변환 유형:MinMax, Polynomial Degree:None\n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 5.764 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 5.465 \n",
      "alpha 10일 때 5 폴드 세트의 평균 RMSE: 5.754 \n",
      "alpha 100일 때 5 폴드 세트의 평균 RMSE: 7.635 \n",
      "\n",
      "## 변환 유형:MinMax, Polynomial Degree:2\n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 5.298 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 4.323 \n",
      "alpha 10일 때 5 폴드 세트의 평균 RMSE: 5.185 \n",
      "alpha 100일 때 5 폴드 세트의 평균 RMSE: 6.538 \n",
      "\n",
      "## 변환 유형:Log, Polynomial Degree:None\n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 4.770 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 4.676 \n",
      "alpha 10일 때 5 폴드 세트의 평균 RMSE: 4.836 \n",
      "alpha 100일 때 5 폴드 세트의 평균 RMSE: 6.241 \n"
     ]
    }
   ],
   "source": [
    "# Ridge의 alpha값을 다르게 적용하고 다양한 데이터 변환방법에 따른 RMSE 추출. \n",
    "alphas = [0.1, 1, 10, 100]\n",
    "#변환 방법은 모두 6개, \n",
    "# 원본 그대로,     표준정규분포,              표준정규분포+다항식 특성\n",
    "# 최대/최소 정규화, 최대/최소 정규화+다항식 특성, 로그변환 \n",
    "scale_methods=[(None, None), ('Standard', None), ('Standard', 2), \n",
    "               ('MinMax', None), ('MinMax', 2), ('Log', None)]\n",
    "\n",
    "for scale_method in scale_methods:\n",
    "    X_data_scaled = get_scaled_data(method=scale_method[0], p_degree=scale_method[1], \n",
    "                                    input_data=X_data)\n",
    "    \n",
    "    print('\\n## 변환 유형:{0}, Polynomial Degree:{1}'.format(scale_method[0], scale_method[1]))\n",
    "    \n",
    "    # Ridge를 이용하여 alpha에 따른 평균 RMSE값 출력\n",
    "    get_linear_reg_eval('Ridge', params=alphas, X_data_n=X_data_scaled, \n",
    "                        y_target_n=y_target, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 끄적끄적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge : Biased 를 많이 줄여주고, variancefmf rkwuekwnsrjt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS 문제 : 만약에 피쳐들간의 강한 연관성이 있을 경우, variance를 갖고 있을 확률이 굉장히 다를 것임 => 각각의 샘플마다 값들의 차이가 엄청 강할 것\n",
    "\n",
    "biased : 훈련 측정치들이 훈련값에 치중되어있는 것 /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙드류 양 \n",
    "\n",
    "\n",
    "\n",
    " underfit = high bias \n",
    "high bias : the algorithm has a very strong preconception \n",
    "which will cause the line to fit poorly into the data\n",
    "\n",
    "overfitting = high variance \n",
    "fitting such high polynomial, then the hopthesis can fit as almost as can fit any function \n",
    "the hypothesis is too variable \n",
    "\n",
    "\n",
    "if the functino overfits to the training set so that the cost function almost equals to 0 which means it will presumably fail to fit, generalize to new examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ n차, 다항식으로 발전시 \n",
    "- bias <=> Error (when low, how well polynomials fit the training data  )\n",
    "- variance : ( deviations from the mean of the training data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
